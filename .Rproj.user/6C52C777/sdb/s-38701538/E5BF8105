{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Analiza ofert dotyczących wynajmu nieruchomości z portalu gumtree.pl\"\nauthor: \"Krzysztof Słomczyński\"\noutput: html_notebook\n---\n\n```{r}\n\n```\n\n# Dlaczego taki temat?\n\nChciałem znaleźć taki temat, którego choć część wykonania będzie miała wymiar praktyczny. Na grupie [MI^2](http://mi2.mini.pw.edu.pl) składającej się głównie ze studentów i absolwentów MiNI PW i MIM UW funkcjonuje projekt [CzasDojazdu](http://github.com/mi2-warsaw/CzasDojazdu). Ma on na celu dostarczenie aplikacji wyszukującej w Warszawie pokojów do wynajęcia pod kątem kryterium czasu dojazdu z mieszkania do pracy. Przeglądając go zauważyłem, że część danych pobieranych z portalu [gumtree.pl](gumtree.pl) jest błędnie zapisywanych (metraż), niektóre zaś są zupełnie pomijane (czy można palić lub trzymać zwierzęta, jaka jest preferowana płeć). Postanowiłem udoskonalić scraper funkcjonujący w tym projekcie, a na świeżo pobranych danych spróbowac zbudować model przewidujący ceny wynajmowanych pokoi.\n\n## Udoskonalenie scrapera - zdobycie danych\n\nZ pomocą pakietu `rvest` oraz wtyczki [SelectorGadget](http://selectorgadget.com) działającej w przeglądarce Chromium udało mi się wydobyć ze stron z ofertami interesujące mnie dane. Kod znaduje się w repozytorium projektu [CzasDojazdu](http://github.com/mi2-warsaw/CzasDojazdu). Kolejne rejestry zapisywane są w bazie danych SQLite. Ponieważ wdrożenie kodu na produkcję ze względów organizacyjnych w takich projektach nieco trwa, zdecydowałem się na przerobienie go tak, aby dane zapisywane były do plików *.csv. Przypatrując się pobranym ofertom wiedziałem, że ich liczba przez czas realizacji projektu nie urośnie do dużych rozmiarów.\n\n# Przygotowanie do projektu\n\nW ramach przygotowania się do realizacji projektu ukończyłem dwa kursy.\n\n* Machine Learning at Coursera by Andrew Ng\n* Statistical Learning at Stanford ONLINE by Trevor Hastie and Robert Tibshirani\n\nOraz zapoznałem się z takimi narzędziami jak Crontab, Flume, Hadoop HDFS i Spark (pakiet `sparklyr`).\n\n# Obróbka danych\n\n```{r}\n# Ładowanie bibliotek\n\nlibrary(dplyr)\nlibrary(readr)\nlibrary(stringi)\nlibrary(knitr)\nlibrary(pander)\n```\n\nOferta dotycząca pokoju do wynajęcia na portalu [gumtree.pl](gumtree.pl) może zawierać następujące (powtarzalne) opcje wyboru:\n\n1. Lokalizacja\n  * Miasto, Województwo\n  * Dokładny adres\n2. Do wynajęcia przez\n  * \"---------\"\n  * Właściciel\n  * Agencja\n3. Współdzielenie\n  * Współdzielenie pokoju\n  * Współdzielenie mieszkania/domu\n4. Dostępny\n  * Data w formacie %d/%m/%Y\n5. Rodzaj nieruchomości\n  * \"---------\"\n  * Mieszkanie\n  * Dom\n  * Inne\n6. Wielkość (m2)\n  * Liczba typu Integer\n7. Liczba pokoi\n  * \"---------\"\n  * Kawalerka lub garsoneria\n  * 2 pokoje\n  * 3 pokoje\n  * 4 pokoje\n  * 5 pokoi\n  * 6 lub więcej pokoi\n8. Palący\n  * \"---------\"\"\n  * Tak\n  * Nie\n9. Przyjazne zwierzakom\n  * \"---------\"\"\n  * Tak\n  * Nie\n10. Preferowana płeć\n  * \"---------\"\n  * Mężczyzna\n  * Kobieta\n  * Bez preferencji\n11. Cena\n  * Liczba typu Integer\n  * Proszę o kontakt\n  * Wymiana/zamiana\n\nZbierane są też dane dotyczące daty dodania oferty, link do ogłoszenia, opis i tutuł. Te jednak tym razem nie będą nas interesować ze względu na swój unikalny charakter.\n\nPrzyjrzyjmy się im nieco bliżej.\n\n```{r}\n# Ładowanie danych\n\ndane1 <- read_csv(\"2016-10-26df.csv\")\ndane2 <- read_csv(\"2016-11-17df.csv\")\npokoje <- rbind(dane1, dane2) %>% distinct()\n\nrm(dane1, dane2)\n```\n\n```{r}\n# Dane pod lupą - obróbka\n\ndim(pokoje)\nstr(pokoje)\n```\n\nZ dostępnych kolumn pozostawimy te które są unikalne. Dodatkowo skorzystamy jednak z opisów w celu policzenia ilości występujacych w nich słów.\n\n```{r}\npokoje %>% names()\nnames(pokoje) <-\n  names(pokoje) %>% chartr(\"ąęółćśźż\", \"aeolcszz\", .)\npokoje <-\n  pokoje %>%\n  rename(wielkosc  = `wielkosc_(m2)`) %>%\n  select(-c(data_dodania, href, adres, tytul, dostepny)) %>%\n  mutate(\n    liczba_wyrazow = stri_count_words(opis)\n  )\npokoje %>%\n  select(-opis) %>%\n  lapply(\n    function(x) {\n      x %>%\n        table(useNA = \"always\") %>%\n        sort(decreasing = TRUE) %>%\n        head(20)\n    }\n  )\n```\n\nNajwięcej ofert pochodzi z Krakowa i Warszawy (po około 2500). Dodatkowo stolica jako jedyne miasto ma rozróżnione lokalizacje ze względu na dzielnicę. Nie trudno domyślić się, że najdroższe pokoje do wynajęcia będą w największych miastach. Ponieważ znaczna większość ofert pochodzi z Warszawy i Krakowa, ograniczę się więc do tych dwóch miast. Na dalszym etapie można spróbowac przewidzieć czy oferta jest z dawnej czy z obecnej stolicy.\n\nSprawdźmy rozkład ilości słów w opisach.\n\n```{r}\nhist(\n  pokoje$liczba_wyrazow,\n  50,\n  main = \"Histogram liczby wyrazów w opisie oferty\",\n  xlab = \"Liczba wyrazów\",\n  ylab = \"Liczba ofert\"\n)\n```\n\nNie trudno było się domyślić, że najczęściej występujące opisy będą krótkie.\n\nUsunę oferty zawierające w cenie informację `Proszę o kontakt` oraz te z `Wymiana/zamiana`. Tak samo postąpię z ofertami, które nie dostarczają informacji o powierzchni wynajmowanej przestrzeni. Dla takich kolumn jak `do_wynajęcia_przez`, `wspoldzielenie` i `liczba_pokoi` w miejsce brakujących wartości wstawię `\"Nie podano\"`, ponieważ ciężko w tych przpadkach doszukać się jakiegoś domyślnego ustawienia. Natomiast w przypadku `rodzaj_nieruchomosci` brak podanej wartości przypiszę do istniejącej opcji `Inne`. Kolejno `preferowana_plec` posiada wartość `Bez preferencji` i to ona zostanie przypisana w zamian za `NA`. Kierując się zasadą \"Co nie jest prawem zabronione, jest dozwolone\" założę, że nieokreślone wartości dla kolumn `palacy` oraz `przyjazne_zwierzakom` przyjmują wartości `Tak`. Na koniec `cena` zostaje pozbawiona informacji o walucie i zamieniona na liczbę typu Integer, a klasy odpowiednich zmiennych zostają zamienione na faktory.\n\n```{r}\npokoje <-\n  pokoje %>%\n  filter(\n    grepl((\"Warszawa|Kraków\"), lokalizacja),\n    !(cena %in% c(\"Proszę o kontakt\", \"Wymiana/zamiana\")),\n    !is.na(wielkosc)\n  ) %>%\n  mutate(\n    do_wynajecia_przez = do_wynajecia_przez %>%\n      plyr::mapvalues(NA, \"Nie podano\") %>%\n      as.factor(),\n    wspoldzielenie = wspoldzielenie %>%\n      plyr::mapvalues(NA, \"Nie podano\") %>%\n      as.factor(),\n    liczba_pokoi = liczba_pokoi %>%\n      plyr::mapvalues(NA, \"Nie podano\") %>%\n      as.factor(),\n    rodzaj_nieruchomosci = rodzaj_nieruchomosci %>%\n      plyr::mapvalues(NA, \"Inne\") %>%\n      as.factor(),\n    preferowana_plec = preferowana_plec %>%\n      plyr::mapvalues(NA, \"Bez preferencji\") %>%\n      as.factor(),\n    palacy = palacy %>%\n      plyr::mapvalues(NA, \"Tak\") %>%\n      as.factor(),\n    przyjazne_zwierzakom = przyjazne_zwierzakom %>%\n      plyr::mapvalues(NA, \"Tak\") %>%\n      as.factor(),\n    cena = stri_extract_all_charclass(\n      cena, \"[[:digit:]]\"\n    ) %>%\n      stri_join_list() %>%\n      as.integer()\n  )\n\npokoje %>% summary()\n```\n\nStosując zasadę ograniczonego zaufania (wiele osób mogło pomylić się podczas wystawiania oferty) przyjrzyjmy się bliżej wartościom przyjmowanym przez cenę oraz wielkość. Po nich spodziewalibyśmy się dość silnej korelacji.\n\n```{r}\nplot(cena~wielkosc, pokoje)\n```\n\nWykres zdecydowanie psują pozycje z ceną powyżej 5000 złotych oraz powierzchnią powyżej 600 metrów kwadratowych. Przyjrzyjmy sie bliżej tym ofertom.\n\n```{r}\npokoje %>%\n  filter(cena == 8000) %>%\n  .$opis\n```\n\nZ treści oferty wynika, że cena za jeden pokój dla osoby to 800 pln. Autor oferty dopisał jeden rząd wielkości do ceny. Przypatrzmy się tym od 3000 w górę.\n\n```{r}\npokoje %>%\n  filter(between(cena, 3000, 4000)) %>%\n  .$opis\n```\n\nPowyższe przypadki opisują całe mieszkania (lub domy) do wynajęcia. Cena podana jest za mieszkanie/dom (sumę pokojów). W serwisie [gumtree.pl](gumtree.pl) istnieje osobny dział do wystawiania takich ofert o nazwie `mieszkania i domy do wynajęcia`. Sprawdźmy co dzieje się przy cenach między 2000 a 3000.\n\n```{r}\npokoje %>%\n  filter(between(cena, 2000, 3000)) %>%\n  .$opis\n```\n\nTym razem cena części ofert faktycznie dotyczy jednego pokoju do wynajęcia w dwópokojowym mieszkaniu w pobliżu stacji Metro Ratusz Arsenał. Niestety podany metraż dotyczy całego mieszkania.\n\nPrzyjrzyjmy się teraz skrajnym wielkościom.\n\n```{r}\npokoje %>%\n  filter(wielkosc >= 1000) %>%\n  .$opis\n```\n\nCiekawe, że dwie najbardziej skrajne oferty pod względem wielkości to kopie najbardziej skranych ofert pod względem ceny. Oczywiście zawierają one błąd i zostaną usunięte. Sprawdźmy co z nieco mniejszymi.\n\n```{r}\npokoje %>%\n  filter(between(wielkosc, 200, 600)) %>%\n  .$opis\n```\n\nOferty te dotyczą hoteli pracowniczych lub całych domostw. Tym razem to cena podana jest za pokój, a wielkość opisuje metraż całego mieszaknia/domu. Niestety nie ma żadnej konsekwencji w podawaniu przez oferantów ceny i wielkości powierzchni wynajmu. Raz podany jest metraż całego mieszkania z ceną za pokój i liczbą pokojów. Innym razem podany jest metraż pokoju z ceną za wszystkie pokoje i podaną liczbą pokojów. Żeby ustandaryzować te oferty trzebaby przeprowadzić wyrafinowaną analizę treści opisu, lub wprowadzić poprawki ręcznie, czytając każdą ofertę po kolei. Na potrzeby projektu ograniczę się do usunięcia tak skrajnych przypadków, aż nie uzyskam w miarę rozsądnej korelacji między tymi dwoma wartościami.\n\nPrzyjrzyjmy sie jeszcze ofertom posiadającym wyjątkowo niską cenę (poniżej 100 PLN) i bardzo mały metraż (10 m^2).\n\n```{r}\npokoje %>%\n  filter(\n    cena <= 100,\n    wielkosc <= 10\n  ) %>%\n  .$opis\n```\n\nW tych ofertach zdecydowanie nieprawidłowo podano wielkość. 6 osobowy pokój raczej nie ma 5 m^2, zaś 3-4 osobowy nie ma 1 m^2.\n\nCo się stanie, gdy ograniczę zestaw danych ze względu na cenę i wielkość przyjmując nieco węższe - eliminujące wadliwe oferty - widełki?\n\n```{r}\nsprawdzenie01 <-\n  pokoje %>%\n  select(-opis) %>%\n  filter(\n    between(cena, 100, 1000),\n    between(wielkosc, 10, 30)\n  )\n\nsummary(sprawdzenie01)\nplot(cena~wielkosc, sprawdzenie01)\nfit01 <- lm(cena~wielkosc, sprawdzenie01)\nabline(fit01, col = \"red\")\n```\n\nNieintuicyjnie cena pokojów do wynajęcia spada wraz ze wzrostem metrażu. Może być to spowodowane dalszą niekonsekwencją we wprowadzaniu danych przez oferantów. Na tym etapie postanowiłem przyjrzeć się innym danym z portalu [gumtree.pl](gumtree.pl). Tym razem oferty dotyczą mieszkań i domów do wynajęcia. Ponieważ ofert jest w sumie niemalże 30 tysięcy postanowiłem ograniczyć się do Warszawy (13 tysięcy ofert) już na etapie scrapowania danych.\n\nDla mieszkań i domów zmieniły się dwa atrybuty do nadania ofertom. Zniknęły kolumny `wspoldzielenie` i `preferowana_pleć` zaś pojawiły się `parking` oraz `liczba_lazienek`. Tym razem ciężko o pomyłkę przy wpisywaniu ceny - mieszaknie jest traktowane jako całość i niezależnie od ilości pokojów cena powinna być podana za całość. To samo tyczy się metrażu. Sprawdźmy więc, czy aby napewno tak jest. Najpierw jednak uporządkujmy dane.\n\n```{r}\nmieszkania <- read_csv(\"2016-11-23_Warszawa_df.csv\")\n\nmieszkania %>% names()\nnames(mieszkania) <-\n  names(mieszkania) %>% chartr(\"ąęółćśźż\", \"aeolcszz\", .)\nmieszkania <-\n  mieszkania %>%\n  rename(wielkosc  = `wielkosc_(m2)`) %>%\n  select(-c(data_dodania, href, adres, tytul, dostepny)) %>%\n  mutate(\n    liczba_wyrazow = stri_count_words(opis)\n  )\nmieszkania %>%\n  select(-opis) %>%\n  lapply(\n    function(x) {\n      x %>%\n        table(useNA = \"always\") %>%\n        sort(decreasing = TRUE) %>%\n        head(20)\n    }\n  )\n\nmieszkania <-\n  mieszkania %>%\n  filter(\n    !(cena %in% c(\"Proszę o kontakt\", \"Wymiana/zamiana\")),\n    !is.na(wielkosc)\n  ) %>%\n  mutate(\n    do_wynajecia_przez = do_wynajecia_przez %>%\n      plyr::mapvalues(NA, \"Nie podano\") %>%\n      as.factor(),\n    parking = parking %>%\n      plyr::mapvalues(NA, \"Nie podano\") %>%\n      as.factor(),\n    liczba_pokoi = liczba_pokoi %>%\n      plyr::mapvalues(NA, \"Nie podano\") %>%\n      as.factor(),\n    rodzaj_nieruchomosci = rodzaj_nieruchomosci %>%\n      plyr::mapvalues(NA, \"Inne\") %>%\n      as.factor(),\n    liczba_lazienek = liczba_lazienek %>%\n      plyr::mapvalues(NA, \"Nie podano\") %>%\n      as.factor(),\n    palacy = palacy %>%\n      plyr::mapvalues(NA, \"Tak\") %>%\n      as.factor(),\n    przyjazne_zwierzakom = przyjazne_zwierzakom %>%\n      plyr::mapvalues(NA, \"Tak\") %>%\n      as.factor(),\n    cena = stri_extract_all_charclass(\n      cena, \"[[:digit:]]\"\n    ) %>%\n      stri_join_list() %>%\n      as.integer()\n  )\n\nmieszkania %>% summary()\n```\n\nPonownie skrajne wartości ceny i wielkości są podejrzane. Przypatrzmy się im bliżej.\n\n```{r}\nplot(cena~wielkosc, mieszkania)\n\nsprawdzenie11 <-\n  mieszkania %>%\n  filter(\n    cena <= 100000,\n    wielkosc <= 1000\n  )\n\nplot(cena~wielkosc, sprawdzenie11)\n\nsprawdzenie12 <-\n  mieszkania %>%\n  filter(\n    cena <= 10000,\n    wielkosc <= 200\n  )\n\nplot(cena~wielkosc, sprawdzenie12)\n\nsprawdzenie13 <-\n  mieszkania %>%\n  filter(\n    between(cena, 1000, 5000),\n    between(wielkosc, 20, 100)\n  )\n\nplot(cena~wielkosc, sprawdzenie13)\n\nsprawdzenie14 <-\n  mieszkania %>%\n  filter(\n    between(cena, 1000, 15000),\n    between(wielkosc, 20, 400)\n  )\n\nplot(cena~wielkosc, sprawdzenie14)\n\nsprawdzenie15 <-\n  mieszkania %>%\n  filter(\n    between(cena, 1000, 10000),\n    between(wielkosc, 20, 200)\n  )\n\nplot(cena~wielkosc, sprawdzenie15)\n\nsprawdzenie16 <-\n  mieszkania %>%\n  filter(\n    between(cena, 1000, 10000),\n    between(wielkosc, 20, 100)\n  )\n\nplot(cena~wielkosc, sprawdzenie16)\n```\n\nTym razem dane wyglądają znacznie bardziej obiecująco. Da się zauważyć korelację między wielkością mieszkania a ceną. Kawalerki zaczynają się od około 20 m^2. Duże 3-4 pokojowe mieszkania liczą sobie do 100 m^2. Skrajne wartości tej skali mają stosunek 1:4. W taki sam sposób dobrano widełki do cen. Są to typowe przedziały cen wynajmu i wielkości mieszkań.\n\n```{r}\ndane <-\n  sprawdzenie13 %>%\n  select(-opis)\nsummary(dane)\n```\n\n# Regresja liniowa\n\n## Funkcja liniowa\n\n```{r}\nplot(cena~wielkosc, dane)\nfit11 <- lm(cena~wielkosc, dane)\nsummary(fit11)\nabline(fit11, col = \"red\", lwd = 2)\n```\n\nZobaczmy jak cena zależy od pozostałych predykatów.\n\n```{r}\nfit12 <-\n  lm(cena~., dane)\nsummary(fit12)\nplot(fit12)\n```\n\nOkazuje się, że predykaty `palacy` oraz `przyjazne_zwierzakom` nie są istotne w zbudowanym modelu. Dla uproszczenia go usuniemy te dwie kolumny. Pozostałe nieistotne parametry należą do grup czynników, z których część jest istotna, dlatego nie zostaną usunięte (należałoby wtedy usunąć też te istotne). Można zaobserwować, że stworzona nowa zmienna dotycząca liczby słów w ofercie jest bardzo istotnym predykatem w naszym modelu.\n\n```{r}\nfit13 <-\n  lm(cena~.-palacy-przyjazne_zwierzakom, dane)\nsummary(fit13)\nplot(fit13)\n```\n\nSpróbujmy wykorzystać interakcję miedzy dwoma predykatami - `lokalizacja` i `wielkosc`.\n\n```{r}\nfit14 <-\n  lm(cena~.+lokalizacja*wielkosc, dane)\nsummary(fit14)\nplot(fit14)\n```\n\nOkazuje się, że ta zależność jest istotna dla modelu. Otrzymujemy większe o 1.5% Adjusted R^2.\n\n## Wielomiany\n\nSpróbujmy teraz dopasować model nieliniowy. Najpierw od samej wielkości mieszkania.\n\n```{r}\nplot(cena~wielkosc, dane)\nfit21 <-\n  lm(cena~wielkosc+I(wielkosc^2), dane)\nsummary(fit21)\npoints(dane$wielkosc, fitted(fit21), col = \"blue\", pch = 20)\nabline(fit11, col = \"red\", lwd = 2)\n```\n\nPodsumowanie komunikuje nam, że wielkość w drugiej potędze jest istotnym czynnikiem. Jednakże widać na powyższym wykresie i po wartości Adjusted R^2 jak nieznacznie różnią się od siebie krzywe predykcyjne.\n\nZ ciekawości sprawdźmy jak będzie wyglądał model dla jeszcze większego stopnia wielomianu.\n\n```{r}\nplot(cena~wielkosc, dane)\nfit22 <-\n  lm(cena~poly(wielkosc, 6), dane)\nsummary(fit22)\npoints(dane$wielkosc, fitted(fit22), col = \"green\", pch = 20)\npoints(dane$wielkosc, fitted(fit21), col = \"blue\", pch = 20)\nabline(fit11, col = \"red\", lwd = 2)\n# contrast() - for qualitative predictors\n```\n\nMożemy zauważyć, że współczynnik 5 stopnia nie jest istotny dla modelu. Dodatkowo funkcja w prawym przedziale dziedziny zaczyna zbyt silnie dopasowywać się do danych (zwłaszcza na samym krańcu).\n\n## Kroswalidacja\n\nTym razem do wyznaczenia błędu naszego modelu posłużymy się metodą kroswalidacji. W tym celu załadujemy odpowiednią bibliotekę ułatwiającą dalszą pracę.\n\n```{r}\nlibrary(boot)\n```\n\nNajpierw wykorzystamy `LOOCV` czyli `Leave One Out Cross Validation`.\n\n```{r}\nfit31 <- glm(cena~wielkosc, data = dane)\n# LOOCV <- cv.glm(dane, fit31)\n# save(LOOCV, file = \"LOOCV.Rda\")\nLOOCV <- get(load(\"LOOCV.Rda\"))\nLOOCV$delta\n```\n\n`LOOCV` tworzy tyle modeli ile jest obserwacji w zestawie danych, za każdym razem pomijając jedeną z nich. Następnie określa błąd sprawdzając różnicę między pominiętą obserwacją a jej przewidywaniem wynikającym z powstałego modelu. Błąd ten określa wartość delta zwróconego obiektu. Pierwsza liczba jest po prostu błędem wyliczonym na podstawie całego danych, druga zaś koryguje ten błąd ze względu na fakt, iż zestaw danych uczących był mniejszy (w tym wypadku zawsze o jedną pozycję). W tym wypadku nie widać żadnej różnicy. Efekt ten będzie bardziej widoczny dla K krotnej kroswalidacji.\n\nMetoda cv.glm jest bardzo powolna. Dlatego efekt jej działania zapisałem wcześniej do pliku, który teraz zostaje wczytany. Czas wykonywania tej operacji trwał kilka minut. Dla znacznego przyspieszenia działania tej funkcji posłużę się następującą formułą uwzględniającą wpływ i-tej obserwacji na dopasowanie do niej krzywej.\n\n```{r}\nloocv.glm <-\n  function(fit) {\n    h <- lm.influence(fit)$h\n    mean((residuals(fit)/(1-h))^2)\n  }\n\nloocv.glm(fit31)\n```\n\nPowodem dla którego metoda cv.glm nie korzysta docelowo z tej formuły jest fakt, że nie funkcjonuje ona w wypadku regresji logistycznej.\n\nTeraz sprawdzimy jakie błędy będą towarzyszyć wielomianom kolejnych stopni i czy opłaca się je zastosować.\n\n```{r}\n# cvBlad <- rep(0, 6)\n# stopien <- 1:6\n# for (d in stopien) {\n#   fit32 <- glm(cena~poly(wielkosc, d), data = dane)\n#   cvBlad[d] <- loocv.glm(fit32)\n# }\n# \n# plot(stopien, cvBlad)\n\ncvBlad <-\n  stopien %>%\n  sapply(\n    function(x) {\n      fit32 <- glm(cena~poly(wielkosc, x), data = dane)\n      loocv.glm(fit32)\n    }\n  )\n\nplot(stopien, cvBlad, type = \"b\")\n```\n\nNa wykresie można zauważyć, że błąd przestaje maleć dla wielmianu 4 stopnia.\n\nTeraz spróbujemy przeprowadzić K krotną kroswalidację. Standardowo za K przyjmuje się wartości 5 lub 10. W tym wypadku przyjmę tę większą.\n\n```{r}\ncvBladK10 <-\n  stopien %>%\n  sapply(\n    function(x) {\n      cv.glm(dane, fit32, K = 10)$delta[1]\n    }\n  )\n\nplot(stopien, cvBlad, type = \"b\")\nlines(stopien, cvBladK10, type = \"b\", col = \"red\")\n```\n\nK krotna kroswalidacja jest bardziej stabilną metodą. W tym przypadku widać jak podpowiada nam, że już w zasadzie funkcja liniowa jest wystarczającym modelem.\n\n## Dobór modelu z wieloma predykatami\n\nPowyższy przykład pozwolił nam określić jaki stopień wielomianu jednego predykatu będzie odpowiedni dla naszego modelu. Tym razem chcemy jednak dobrać odpowiedni model z wieloma predykatami. Jakie są nasze opcje?\n\n### Best Subset Regression\n\nMetoda ta porównuje wszytkie możliwe modele regresji o wszystkich możliwych wielkościach (liczbie biorących udział w tworzeniu modelu predykatów) w poszukiwaniu najlepszego modelu dla każdego z rozmiarów. W sumie wykonuje 2^p modeli, gdzie p to lizcba predykatów (w naszym przypadku 2^11 czyli 2048) W osiągnięciu tego celu pomoże nam biblioteka `leaps`.\n\n```{r}\nlibrary(leaps)\n```\n\n```{r}\nfit41 <- regsubsets(cena~., dane, nvmax = 11)\nsum41 <- summary(fit41)\nsum41\nplot(sum41$cp, xlab = \"Liczba predykatów\", ylab = \"Cp\")\npoints(11, sum41$cp[11], pch = 20, col = \"red\")\nplot(fit41, scale = \"Cp\")\ncoef(fit41, 11)\n```\n\nNiestety, w tym wypadku nie widać czym charakteryzuje się ta metoda. Nie zakłada ona zagnieżdżania podzbiorów predykatów. Zagnieżdzanie polega na tym, że każdy kolejny większy model musi opierać się na czynnikach wchodzących w skład poprzedniego modelu. Tutaj mobłoby dojść do sytuacji, gdzie dla kilku pierwszych podzbiorów przy konkretnym czynniku występują gwiazdki, następnie zaś nie pojawiają się.\n\nCp jest miarą błędu predykcji. Jak widać w tym przypadku najmniejszy błąd występuje dla modelu o największej liczbie predykatów. Wcale nie musiało tak być i z większą liczbą czynników błąd mógłby zacząć rosnąć.\n\n### Forward Stepwise Selection\n\nTa metodą jest jest \"chciwa\" w tym sensie, że zagnieżdza kolejne podzbiory czynników. Nie tworzy zatem każdej możliwej kombinacji predykatów. Już raz dobrany czynnik wykorzystywany jest w następnym modelu. Przy dobieraniu kolejnego predykatu metoda ta dobiera najlepszą opcję porównując tylko p modeli. Zatem ogółem liczba operacji wynosi około (p^2)/2 (w naszym przypadku około 60, czyli tylko 3% w porównaniu z poprzednią metodą.\n\n```{r}\nfit42 <- regsubsets(cena~., dane, nvmax = 11, method = \"forward\")\nsum42 <- summary(fit42)\nsum42\nplot(sum42$cp, xlab = \"Liczba predykatów\", ylab = \"Cp\")\npoints(11, sum42$cp[11], pch = 20, col = \"red\")\nplot(fit42, scale = \"Cp\")\ncoef(fit42, 11)\n```\n\n### Backward Stepwise Selection\n\nMetoda ta różni się od FSS tym, że zaczyna porównywać modele zbudowane na wszystkich predykatach i z każdym kolejnym krokiem odejmuję jeden z nich (najmniej istotny) z zestawu. Minusem tej metody jest to, że nie można użyć jej na zestawie danych gdzie występuje więcej kolumn niż wierszy.\n\n```{r}\nfit43 <- regsubsets(cena~., dane, nvmax = 11, method = \"backward\")\nsum43 <- summary(fit43)\nsum43\nplot(sum43$cp, xlab = \"Liczba predykatów\", ylab = \"Cp\")\npoints(11, sum43$cp[11], pch = 20, col = \"red\")\nplot(fit43, scale = \"Cp\")\ncoef(fit43, 11)\n```\n\n### Walidacja\n\nTym razem podzielimy obserwacje na dwa zestawy - treningowy i walidacyjny.\n\n```{r}\nset.seed(44)\ntrening44 <- sample(1:nrow(dane), 9000)\nfit44 <- regsubsets(cena~., dane[trening44, ], nvmax = 11, method = \"forward\")\n```\n\nTeraz dokonamy predykcji na obserwacjach z zestawu testowego.\n\n```{r}\ntest44 <- model.matrix(cena~., dane[-trening44, ])\nvalBlad <-\n  1:length(dane) %>%\n  sapply(\n    function(x) {\n      coefi <- coef(fit44, id = x)\n      pred <- test44[, names(coefi)]%*%coefi\n      mean((dane$cena[-trening44]-pred)^2)\n    }\n  )\nplot(\n  sqrt(valBlad),\n  ylim = c(400, 900),\n  xlab = \"Rozmiar modelu\",\n  ylab = \"Średnia kwadratowa błędów\",\n  pch = 19,\n  type = \"b\"\n)\npoints(sqrt(fit44$rss[-1]/9000), col = \"red\", pch = 19, type = \"b\")\nlegend(\"topright\", legend = c(\"Trening\", \"Walidacja\"), col = c(\"red\", \"black\"), pch = 19)\n```\n\nNa powyższym wykresie można zauważyć, że pomimo konsekwentnego spadku błędu treningowego, już przy rozmiarze modelu wynoszącym 3 błąd walidacji wypłaszcza się.\n\nNa koniec operacje prowadzące do otrzymania takiego rezultatu zostaną ubrane w jedna funkcję.\n\n```{r}\npredict.regsubsets <-\n  function(obiekt, dane, id, ...) {\n    form <- as.formula(obiekt$call[[2]])\n    mat <- model.matrix(form, dane)\n    coefi <- coef(obiekt, id = id)\n    mat[, names(coefi)]%*%coefi\n  }\n```\n\n### Kroswalidacja\n\nTym razem dobierzemy model korzystając z 10 krotnej kroswalidacji.\n\n```{r}\nset.seed(45)\nfolds <- sample(rep(1:10, length = nrow(dane)))\ntable(folds)\n# cvBledy <-\n#   1:10 %>%\n#   sapply(\n#     function (k) {\n#       best.fit <- regsubsets(cena~., dane[folds!=k, ], nvmax = 11, method = \"forward\")\n#       mapply(\n#           function(K, i) {\n#             pred <- predict(BEST.FIT, dane[folds==K, ], id = i)\n#             mean((dane$cena[folds==K]-pred)^2)\n#           },\n#           k, 1:length(dane),\n#           MoreArgs = list(BEST.FIT = best.fit)\n#         )\n#     }\n#   )\n\ncvBledy <- matrix(NA, 10, 11)\nfor (k in 1:10) {\n  best.fit <- regsubsets(cena~., dane[folds!=k, ], nvmax = 11, method = \"forward\")\n  for (i in 1:length(dane)) {\n    pred <- predict.regsubsets(best.fit, dane[folds==k, ], id = i)\n    cvBledy[k, i] <- mean((dane$cena[folds==k]-pred)^2)\n  }\n}\nrmse.cv <- sqrt(apply(cvBledy, 2, mean))\n# plot(\n#   sqrt(valBlad),\n#      ylim = c(400, 900),\n#      xlab = \"Rozmiar modelu\",\n#      ylab = \"Średnia kwadratowa błędów\",\n#      pch = 19,\n#      type = \"b\"\n# )\n# points(rmse.cv, col = \"red\", pch = 19, type = \"b\")\n# legend(\"topright\", legend = c(\"10 krotna Kroswalidacja\", \"Walidacja\"), col = c(\"red\", \"black\"), pch = 19)\n\nplot(\n  sqrt(valBlad),\n  ylim = c(400, 900),\n  xlab = \"Rozmiar modelu\",\n  ylab = \"Średnia kwadratowa błędów\",\n  pch = 19,\n  type = \"b\"\n)\npoints(sqrt(fit44$rss[-1]/9000), col = \"red\", pch = 19, type = \"b\")\npoints(rmse.cv, col = \"blue\", pch = 19, type = \"b\")\nlegend(\n  \"topright\",\n  legend = c(\"10 krotna Kroswalidacja\", \"Trening\", \"Walidacja\"),\n  col = c(\"blue\", \"red\", \"black\"),\n  pch = 19\n)\n```\n\n### Regularyzacja Tichonowa\n\n### Lasso",
    "created" : 1479825158525.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2600130567",
    "id" : "E5BF8105",
    "lastKnownWriteTime" : 1480017239,
    "last_content_update" : 1480017239585,
    "path" : "~/GitHub/tuatara/tuatara_mieszkania.Rmd",
    "project_path" : "tuatara_mieszkania.Rmd",
    "properties" : {
        "chunk_output_type" : "inline",
        "tempName" : "Untitled1"
    },
    "relative_order" : 6,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}
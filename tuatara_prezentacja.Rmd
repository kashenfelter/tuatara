---
title: "Analiza ofert dotyczących wynajmu nieruchomości z portalu gumtree.pl"
author: "Krzysztof Słomczyński"
date: "26 listopada 2016"
output:
  revealjs::revealjs_presentation:
    theme: night
    reveal_options:
      slideNumber: true
---

```{r setup, include = FALSE}
library(knitr)
library(pander)
opts_chunk$set(
    comment = "",
    fig.width = 12,
    echo = FALSE,
    eval = TRUE,
    message = FALSE,
    warning = FALSE,
    tidy.opts = list(
        keep.blank.line = TRUE,
        width.cutoff = 150
        ),
    options(width = 150)
)
```

```{r}
library(dplyr)
library(readr)
library(stringi)
library(htmltools)
```

## Dlaczego taki temat?

- Praktyczny wymiar projektu
- [CzasDojazdu](http://github.com/mi2-warsaw/CzasDojazdu)
- Błędnie zapisywane dane (metraż), niektóre pomijane (palenie, zwierzęta, płeć)

## Cel

- Udoskonalenie scrapera ([rvest](http://cran.r-project.org/web/packages/rvest/index.html) i [SelectorGadget](http://selectorgadget.com))
- Zbudowanie modelu przewidującego ceny wynajmowanych pokojów
- Dostarczenie aplikacji bazującej na modelu

## Struktura danych

<img style="float: left;" src="oferta_01.png" width="45%" height="45%">
<img style="float: right;" src="oferta_02.png" width="50%" height="50%">

## Przygotowanie do projektu

Ukończenie kursów:

- Machine Learning at Coursera by Andrew Ng (18 godzin)
- Statistical Learning at Stanford ONLINE by Trevor Hastie and Robert Tibshirani (15 godzin)

Zapoznanie się z narzędziami:

- Hadoop HDFS
- Spark (pakiet [sparklyr](http://spark.rstudio.com/))
- Pakiety do różnego rodzaju regresji ([boot](http://cran.r-project.org/web/packages/boot/index.html), [leaps](http://cran.r-project.org/web/packages/leaps/index.html), [glmnet](http://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html))
- Pakiety do tworzenia prezentacji [revealjs](http://cran.r-project.org/web/packages/revealjs/index.html)

# Jeden predyktor

## Dobieranie stopnia wielomianu

```{r}
dane <- read_csv("dane.csv")
dane <-
  dane %>%
  mutate(
    lokalizacja = lokalizacja %>%
      stri_replace_first_regex(", Warszawa", "") %>%
      as.factor(),
    do_wynajecia_przez = do_wynajecia_przez %>% as.factor(),
    parking = parking %>% as.factor(),
    liczba_pokoi = liczba_pokoi %>% as.factor(),
    rodzaj_nieruchomosci = rodzaj_nieruchomosci %>% as.factor(),
    liczba_lazienek = liczba_lazienek %>% as.factor(),
    palacy = palacy %>% as.factor(),
    przyjazne_zwierzakom = przyjazne_zwierzakom %>% as.factor()
  )

fit11 <- lm(cena~wielkosc, dane)
fit21 <- lm(cena~wielkosc+I(wielkosc^2), dane)
fit22 <- lm(cena~poly(wielkosc, 6), dane)

plot(
  cena~wielkosc,
  dane,
  main = "Średnia kwadratowa błędów w funkcji stopnia wielomianu",
  xlab = expression("wielkość [m"^{2}*"]"),
  ylab = "cena [PLN]"
)
abline(fit11, col = "red", lwd = 2)
points(dane$wielkosc, fitted(fit21), col = "blue", pch = 20)
points(dane$wielkosc, fitted(fit22), col = "green", pch = 20)
legend(
  "topleft",
  legend = c(1, 2, 6),
  col = c("red", "blue", "green"),
  pch = 19
)
```

## Kroswalidacja

```{r}
library(boot)

loocv.glm <-
  function(fit) {
    h <- lm.influence(fit)$h
    mean((residuals(fit)/(1-h))^2)
  }

cvBlad <- rep(0, 6)
stopien <- 1:6
for (d in stopien) {
  fit32 <- glm(cena~poly(wielkosc, d), data = dane)
  cvBlad[d] <- loocv.glm(fit32)
}

cvBladK10 <-
  stopien %>%
  sapply(
    function(x) {
      cv.glm(dane, fit32, K = 10)$delta[1]
    }
  )

plot(
  stopien,
  cvBlad %>% sqrt(),
  main = "Średnia kwadratowa błędów w funkcji stopnia wielomianu",
  xlab = "stopień wielomianu [-]",
  ylab = "średnia kwadratowa błędów [PLN]",
  type = "b",
  col = "red"
)
lines(stopien, cvBladK10 %>% sqrt(), type = "b", col = "blue")
legend(
  "topright",
  legend = c("LOOCV", "K-fold"),
  col = c("red", "blue"),
  pch = 19
)
```

# Wiele predyktorów

## Metody dobierania rozmiaru modelu

```{r}
library(leaps)

nPred <-
  function(dane) {
    dane %>%
      sapply(
        function(x) {
          x %>%
            levels() %>%
            length() %>%
            plyr::mapvalues(0, 2, warn_missing = FALSE)-1
        }
      ) %>%
      sum()-1
  }

npDane <- nPred(dane)
fit41 <- regsubsets(cena~., dane, nvmax = npDane)
fit42 <- regsubsets(cena~., dane, nvmax = npDane, method = "forward")
fit43 <- regsubsets(cena~., dane, nvmax = npDane, method = "backward")

set.seed(44)
trening44 <- sample(1:nrow(dane), 9000)
invisible(
  capture.output(
    fit44 <-
      regsubsets(
        cena ~ .,
        dane[trening44,],
        nvmax = nPred(dane[trening44,]),
        method = "forward"
      )
  )
)
test44 <- model.matrix(cena~., dane[-trening44, ])
valBlad <-
  1:(fit44$nvmax-1) %>%
  sapply(
    function(x) {
      coefi <- coef(fit44, id = x)
      pred <- test44[, names(coefi)]%*%coefi
      mean((dane$cena[-trening44]-pred)^2)
    }
  )

predict.regsubsets <-
  function(obiekt, dane, id, ...) {
    form <- as.formula(obiekt$call[[2]])
    mat <- model.matrix(form, dane)
    coefi <- coef(obiekt, id = id)
    mat[, names(coefi)]%*%coefi
  }

K <- 10
set.seed(45)
folds <- sample(rep(1:K, length = nrow(dane)))
cvBledy <- matrix(NA, K, npDane)
for (k in 1:K) {
  invisible(
    capture.output(
      best.fit <-
        regsubsets(
          cena~.,
          dane[folds!=k, ],
          nvmax = nPred(dane[folds!=k, ]),
          method = "forward"
        )
    )
  )
  for (i in 1:(fit44$nvmax-1)) {
    pred <- predict.regsubsets(best.fit, dane[folds==k, ], id = i)
    cvBledy[k, i] <- mean((dane$cena[folds==k]-pred)^2)
  }
}
rmse.cv <- sqrt(apply(cvBledy, 2, mean))
```

```{r}
library(glmnet)

x <- model.matrix(cena~.-1, dane)
y <- dane$cena

fit45 <- glmnet(x, y, alpha = 0)
cvRidge <- cv.glmnet(x, y, alpha = 0)

daneNorm <-
  dane %>%
  mutate(
    cena = (cena-mean(cena))/max(cena),
    wielkosc = (wielkosc-mean(wielkosc))/max(wielkosc),
    liczba_wyrazow = (liczba_wyrazow-mean(liczba_wyrazow))/max(liczba_wyrazow)
  )

xn <- model.matrix(cena~.-1, daneNorm)
yn <- daneNorm$cena

fit45N <- glmnet(xn, yn, alpha = 0)

cvRidgeN <- cv.glmnet(xn, yn, alpha = 0)
```

```{r}
fit46 <- glmnet(x, y)
cvLasso <- cv.glmnet(x, y)

fit47 <- glmnet(xn, yn)
cvLassoN <- cv.glmnet(xn, yn)

lasso.tr <- glmnet(x[trening44, ], y[trening44])
pred <- predict(lasso.tr, x[-trening44, ])
rmse <- sqrt(apply((y[-trening44]-pred)^2, 2, mean))

lam.best <- lasso.tr$lambda[order(rmse)[1]]
```

```{r}
p <- npDane
n <- 100

rozmiary <-
  data_frame(
    Metoda = c(
        "Best Subset Regression",
        "Forward Stepwise Selection",
        "Backward Stepwise Selection",
        "Walidacja",
        "Kroswalidacja",
        "Ridge Regression",
        "Lasso"
      ),
    `Liczba modeli` = c(
        HTML("2<sup>p</sup>"),
        HTML("<sup>p<sup>2</sup></sup>&frasl;<sub>2</sub>"),
        HTML("<sup>p<sup>2</sup></sup>&frasl;<sub>2</sub>"),
        HTML("<sup>p<sup>2</sup></sup>&frasl;<sub>2</sub>"),
        HTML("K <sup>p<sup>2</sup></sup>&frasl;<sub>2</sub>"),
        HTML("K n<sub>&lambda;</sub>"),
        HTML("K n<sub>&lambda;</sub>")
      ),
    `p=30 K=10 n=100` = c(
      HTML("10<sup>12</sup>"),
      round((p^2)/2),
      round((p^2)/2),
      round((p^2)/2),
      round(K*(p^2)/2),
      K*n,
      K*n
    ),
    `Najmniejszy błąd` = c(
      (fit41$rss/nrow(dane)) %>% min() %>% sqrt() %>% round(),
      (fit42$rss/nrow(dane)) %>% min() %>% sqrt() %>% round(),
      (fit43$rss/nrow(dane)) %>% min() %>% sqrt() %>% round(),
      valBlad %>% min() %>% sqrt() %>% round(),
      rmse.cv %>% na.omit() %>% min() %>% round(),
      cvRidge$cvm %>% min() %>% sqrt() %>% round(),
      cvLasso$cvm %>% min() %>% sqrt() %>% round()
    )
  )

pander(rozmiary %>% pandoc.table(split.tables = Inf))
```

## Walidacja i Kroswalidacja

```{r}
plot(
  sqrt(fit44$rss[-1]/9000),
  ylim = c(400, 900),
  xlab = "rozmiar modelu [-]",
  ylab = "średnia kwadratowa błędów [PLN]",
  col = "red",
  pch = 19,
  type = "b"
)
points(sqrt(valBlad), col = "blue", pch = 19, type = "b")
points(rmse.cv, col = "green", pch = 19, type = "b")
legend(
  "topright",
  legend = c("Trening", "Walidacja", "10 krotna Kroswalidacja"),
  col = c("red", "blue", "green"),
  pch = 19
)
```

## Regularyzacja - Ridge Regression i Lasso

```{r}
par(mfrow = c(2, 1))
plot(
  cvRidge,
  xlab = expression(log(lambda)~"[-]"),
  ylab = expression("błąd średniokwadratowy [PLN"^{2}*"]"),
  mgp = c(2.5, 1, 0)
)
plot(
  cvLasso,
  xlab = expression(log(lambda)~"[-]"),
  ylab = expression("błąd średniokwadratowy [PLN"^{2}*"]"),
  mgp = c(2.5, 1, 0)
)
```

# Napotkane problemy i wnioski

## Napotkane problemy

```{r}
pokoje <- read_csv("pokoje.csv")

pokoje <-
  pokoje %>%
  mutate(
    lokalizacja = lokalizacja %>%
      stri_replace_first_regex(", Warszawa", "") %>%
      as.factor(),
    do_wynajecia_przez = do_wynajecia_przez %>% as.factor(),
    wspoldzielenie = wspoldzielenie %>% as.factor(),
    liczba_pokoi = liczba_pokoi %>% as.factor(),
    rodzaj_nieruchomosci = rodzaj_nieruchomosci %>% as.factor(),
    preferowana_plec = preferowana_plec %>% as.factor(),
    palacy = palacy %>% as.factor(),
    przyjazne_zwierzakom = przyjazne_zwierzakom %>% as.factor()
  )

sprawdzenie01 <-
  pokoje %>%
  filter(
    between(cena, 50, 1500),
    between(wielkosc, 10, 100)
  )

plot(
  cena~wielkosc,
  sprawdzenie01,
  main = "Zależność ceny od metrażu",
  xlab = expression("wielkość [m"^{2}*"]"),
  ylab = "cena [PLN]"
)
fit01 <- lm(cena~wielkosc, sprawdzenie01)
abline(fit01, col = "red", lwd = 2)
```

## Wnioski

- Wyrafinowana analiza treści opisu
- Propozycja dokładnego opisu atrybutów w formularzu na [gumtree.pl](gumtree.pl)

## Kod i inne projekty

- Kod napisany na potrzeby tego projektu na [github](http://github.com/krzyslom/tuatara)
- [Raport](http://mi2.mini.pw.edu.pl:3838/pracuj/ml) z innego projektu w którym brałem udział
---
title: "Analiza ofert dotyczących wynajmu nieruchomości z portalu gumtree.pl"
author: "Krzysztof Słomczyński"
output:
  html_document: default
  html_notebook: default
---

```{r}

```

# Dlaczego taki temat?

Chciałem znaleźć taki temat, którego choć część wykonania będzie miała wymiar praktyczny. Na grupie [MI^2](http://mi2.mini.pw.edu.pl) składającej się głównie ze studentów i absolwentów MiNI PW i MIM UW funkcjonuje projekt [CzasDojazdu](http://github.com/mi2-warsaw/CzasDojazdu). Ma on na celu dostarczenie aplikacji wyszukującej w Warszawie pokojów do wynajęcia pod kątem kryterium czasu dojazdu z mieszkania do pracy. Przeglądając go zauważyłem, że część danych pobieranych z portalu [gumtree.pl](gumtree.pl) jest błędnie zapisywanych (metraż), niektóre zaś są zupełnie pomijane (czy można palić lub trzymać zwierzęta, jaka jest preferowana płeć). Postanowiłem udoskonalić scraper funkcjonujący w tym projekcie, a na świeżo pobranych danych spróbowac zbudować model przewidujący ceny wynajmowanych pokoi.

## Udoskonalenie scrapera - zdobycie danych

Z pomocą pakietu `rvest` oraz wtyczki [SelectorGadget](http://selectorgadget.com) działającej w przeglądarce Chromium udało mi się wydobyć ze stron z ofertami interesujące mnie dane. Kod znaduje się w repozytorium projektu [CzasDojazdu](http://github.com/mi2-warsaw/CzasDojazdu). Kolejne rejestry zapisywane są w bazie danych SQLite. Ponieważ wdrożenie kodu na produkcję ze względów organizacyjnych w takich projektach nieco trwa, zdecydowałem się na przerobienie go tak, aby dane zapisywane były do plików *.csv. Przypatrując się pobranym ofertom wiedziałem, że ich liczba przez czas realizacji projektu nie urośnie do dużych rozmiarów.

# Przygotowanie do projektu

W ramach przygotowania się do realizacji projektu ukończyłem dwa kursy.

* Machine Learning at Coursera by Andrew Ng
* Statistical Learning at Stanford ONLINE by Trevor Hastie and Robert Tibshirani

Oraz zapoznałem się z takimi narzędziami jak Crontab, Flume, Hadoop HDFS i Spark (pakiet `sparklyr`).

# Obróbka danych

```{r}
# Ładowanie bibliotek

library(dplyr)
library(readr)
library(stringi)
```

Oferta dotycząca pokoju do wynajęcia na portalu [gumtree.pl](gumtree.pl) może zawierać następujące (powtarzalne) opcje wyboru:

1. Lokalizacja
  * Miasto, Województwo
  * Dokładny adres
2. Do wynajęcia przez
  * "---------"
  * Właściciel
  * Agencja
3. Współdzielenie
  * Współdzielenie pokoju
  * Współdzielenie mieszkania/domu
4. Dostępny
  * Data w formacie %d/%m/%Y
5. Rodzaj nieruchomości
  * "---------"
  * Mieszkanie
  * Dom
  * Inne
6. Wielkość (m2)
  * Liczba typu Integer
7. Liczba pokoi
  * "---------"
  * Kawalerka lub garsoneria
  * 2 pokoje
  * 3 pokoje
  * 4 pokoje
  * 5 pokoi
  * 6 lub więcej pokoi
8. Palący
  * "---------"
  * Tak
  * Nie
9. Przyjazne zwierzakom
  * "---------"
  * Tak
  * Nie
10. Preferowana płeć
  * "---------"
  * Mężczyzna
  * Kobieta
  * Bez preferencji
11. Cena
  * Liczba typu Integer
  * Proszę o kontakt
  * Wymiana/zamiana

Zbierane są też dane dotyczące daty dodania oferty, link do ogłoszenia, opis i tutuł. Te jednak tym razem nie będą nas interesować ze względu na swój unikalny charakter.

Przyjrzyjmy się im nieco bliżej.

```{r}
# Ładowanie danych

dane1 <- read_csv("2016-10-26df.csv")
dane2 <- read_csv("2016-11-17df.csv")
pokoje <- rbind(dane1, dane2) %>% distinct()

rm(dane1, dane2)
```

```{r}
# Dane pod lupą - obróbka

dim(pokoje)
str(pokoje)
```

Z dostępnych kolumn pozostawimy te które są unikalne. Dodatkowo skorzystamy jednak z opisów w celu policzenia ilości występujacych w nich słów.

```{r}
pokoje %>% names()
names(pokoje) <-
  names(pokoje) %>% chartr("ąęółćśźż", "aeolcszz", .)
pokoje <-
  pokoje %>%
  rename(wielkosc  = `wielkosc_(m2)`) %>%
  select(-c(data_dodania, href, adres, tytul, dostepny)) %>%
  mutate(
    liczba_wyrazow = stri_count_words(opis)
  )
pokoje %>%
  select(-opis) %>%
  lapply(
    function(x) {
      x %>%
        table(useNA = "always") %>%
        sort(decreasing = TRUE) %>%
        head(20)
    }
  )
```

Najwięcej ofert pochodzi z Krakowa i Warszawy (po około 2500). Dodatkowo stolica jako jedyne miasto ma rozróżnione lokalizacje ze względu na dzielnicę. Nie trudno domyślić się, że najdroższe pokoje do wynajęcia będą w największych miastach. Ponieważ znaczna większość ofert pochodzi z Warszawy i Krakowa, ograniczę się więc do tych dwóch miast. Na dalszym etapie można spróbowac przewidzieć czy oferta jest z dawnej czy z obecnej stolicy.

Sprawdźmy rozkład ilości słów w opisach.

```{r}
hist(
  pokoje$liczba_wyrazow,
  50,
  main = "Histogram liczby wyrazów w opisie oferty",
  xlab = "Liczba wyrazów",
  ylab = "Liczba ofert"
)
```

Nie trudno było się domyślić, że najczęściej występujące opisy będą krótkie.

Usunę oferty zawierające w cenie informację `Proszę o kontakt` oraz te z `Wymiana/zamiana`. Tak samo postąpię z ofertami, które nie dostarczają informacji o powierzchni wynajmowanej przestrzeni. Dla takich kolumn jak `do_wynajęcia_przez`, `wspoldzielenie` i `liczba_pokoi` w miejsce brakujących wartości wstawię `"Nie podano"`, ponieważ ciężko w tych przpadkach doszukać się jakiegoś domyślnego ustawienia. Natomiast w przypadku `rodzaj_nieruchomosci` brak podanej wartości przypiszę do istniejącej opcji `Inne`. Kolejno `preferowana_plec` posiada wartość `Bez preferencji` i to ona zostanie przypisana w zamian za `NA`. Kierując się zasadą "Co nie jest prawem zabronione, jest dozwolone" założę, że nieokreślone wartości dla kolumn `palacy` oraz `przyjazne_zwierzakom` przyjmują wartości `Tak`. Na koniec `cena` zostaje pozbawiona informacji o walucie i zamieniona na liczbę typu Integer, a klasy odpowiednich zmiennych zostają zamienione na faktory.

```{r}
pokoje <-
  pokoje %>%
  filter(
    grepl(("Warszawa|Kraków"), lokalizacja),
    !(cena %in% c("Proszę o kontakt", "Wymiana/zamiana")),
    !is.na(wielkosc)
  ) %>%
  mutate(
    lokalizacja = lokalizacja %>%
      stri_replace_first_regex(", Warszawa", "") %>%
      as.factor(),
    do_wynajecia_przez = do_wynajecia_przez %>%
      plyr::mapvalues(NA, "Nie podano") %>%
      as.factor(),
    wspoldzielenie = wspoldzielenie %>%
      plyr::mapvalues(NA, "Nie podano") %>%
      as.factor(),
    liczba_pokoi = liczba_pokoi %>%
      plyr::mapvalues(NA, "Nie podano") %>%
      as.factor(),
    rodzaj_nieruchomosci = rodzaj_nieruchomosci %>%
      plyr::mapvalues(NA, "Inne") %>%
      as.factor(),
    preferowana_plec = preferowana_plec %>%
      plyr::mapvalues(NA, "Bez preferencji") %>%
      as.factor(),
    palacy = palacy %>%
      plyr::mapvalues(NA, "Tak") %>%
      as.factor(),
    przyjazne_zwierzakom = przyjazne_zwierzakom %>%
      plyr::mapvalues(NA, "Tak") %>%
      as.factor(),
    cena = stri_extract_all_regex(
      cena, "[[:digit:]]"
    ) %>%
      stri_join_list() %>%
      as.integer()
  )

pokoje %>% summary()
```

Stosując zasadę ograniczonego zaufania (wiele osób mogło pomylić się podczas wystawiania oferty) przyjrzyjmy się bliżej wartościom przyjmowanym przez cenę oraz wielkość. Po nich spodziewalibyśmy się dość silnej korelacji.

```{r}
plot(cena~wielkosc, pokoje)
```

Wykres zdecydowanie psują pozycje z ceną powyżej 5000 złotych oraz powierzchnią powyżej 600 metrów kwadratowych. Przyjrzyjmy sie bliżej tym ofertom.

```{r}
pokoje %>%
  filter(cena == 8000) %>%
  .$opis
```

Z treści oferty wynika, że cena za jeden pokój dla osoby to 800 pln. Autor oferty dopisał jeden rząd wielkości do ceny. Przypatrzmy się tym od 3000 w górę.

```{r}
pokoje %>%
  filter(between(cena, 3000, 4000)) %>%
  .$opis
```

Powyższe przypadki opisują całe mieszkania (lub domy) do wynajęcia. Cena podana jest za mieszkanie/dom (sumę pokojów). W serwisie [gumtree.pl](gumtree.pl) istnieje osobny dział do wystawiania takich ofert o nazwie `mieszkania i domy do wynajęcia`. Sprawdźmy co dzieje się przy cenach między 2000 a 3000.

```{r}
pokoje %>%
  filter(between(cena, 2000, 3000)) %>%
  .$opis
```

Tym razem cena części ofert faktycznie dotyczy jednego pokoju do wynajęcia w dwópokojowym mieszkaniu w pobliżu stacji Metro Ratusz Arsenał. Niestety podany metraż dotyczy całego mieszkania.

Przyjrzyjmy się teraz skrajnym wielkościom.

```{r}
pokoje %>%
  filter(wielkosc >= 1000) %>%
  .$opis
```

Ciekawe, że dwie najbardziej skrajne oferty pod względem wielkości to kopie najbardziej skranych ofert pod względem ceny. Oczywiście zawierają one błąd i zostaną usunięte. Sprawdźmy co z nieco mniejszymi.

```{r}
pokoje %>%
  filter(between(wielkosc, 200, 600)) %>%
  .$opis
```

Oferty te dotyczą hoteli pracowniczych lub całych domostw. Tym razem to cena podana jest za pokój, a wielkość opisuje metraż całego mieszaknia/domu. Niestety nie ma żadnej konsekwencji w podawaniu przez oferantów ceny i wielkości powierzchni wynajmu. Raz podany jest metraż całego mieszkania z ceną za pokój i liczbą pokojów. Innym razem podany jest metraż pokoju z ceną za wszystkie pokoje i podaną liczbą pokojów. Żeby ustandaryzować te oferty trzebaby przeprowadzić wyrafinowaną analizę treści opisu, lub wprowadzić poprawki ręcznie, czytając każdą ofertę po kolei. Na potrzeby projektu ograniczę się do usunięcia tak skrajnych przypadków, aż nie uzyskam w miarę rozsądnej korelacji między tymi dwoma wartościami.

Przyjrzyjmy sie jeszcze ofertom posiadającym wyjątkowo niską cenę (poniżej 100 PLN) i bardzo mały metraż (10 m^2).

```{r}
pokoje %>%
  filter(
    cena <= 100,
    wielkosc <= 10
  ) %>%
  .$opis
```

W tych ofertach zdecydowanie nieprawidłowo podano wielkość. 6 osobowy pokój raczej nie ma 5 m^2, zaś 3-4 osobowy nie ma 1 m^2.

Co się stanie, gdy ograniczę zestaw danych ze względu na cenę i wielkość przyjmując nieco węższe - eliminujące wadliwe oferty - widełki?

```{r}
sprawdzenie01 <-
  pokoje %>%
  select(-opis) %>%
  filter(
    between(cena, 100, 1000),
    between(wielkosc, 10, 30)
  )

summary(sprawdzenie01)
plot(cena~wielkosc, sprawdzenie01)
fit01 <- lm(cena~wielkosc, sprawdzenie01)
abline(fit01, col = "red")
```

Nieintuicyjnie cena pokojów do wynajęcia spada wraz ze wzrostem metrażu. Może być to spowodowane dalszą niekonsekwencją we wprowadzaniu danych przez oferantów. Na tym etapie postanowiłem przyjrzeć się innym danym z portalu [gumtree.pl](gumtree.pl). Tym razem oferty dotyczą mieszkań i domów do wynajęcia. Ponieważ ofert jest w sumie niemalże 30 tysięcy postanowiłem ograniczyć się do Warszawy (13 tysięcy ofert) już na etapie scrapowania danych.

Dla mieszkań i domów zmieniły się dwa atrybuty do nadania ofertom. Zniknęły kolumny `wspoldzielenie` i `preferowana_pleć` zaś pojawiły się `parking` oraz `liczba_lazienek`. Tym razem ciężko o pomyłkę przy wpisywaniu ceny - mieszaknie jest traktowane jako całość i niezależnie od ilości pokojów cena powinna być podana za całość. To samo tyczy się metrażu. Sprawdźmy więc, czy aby napewno tak jest. Najpierw jednak uporządkujmy dane.

```{r}
mieszkania <- read_csv("2016-11-23_Warszawa_df.csv")

mieszkania %>% names()
names(mieszkania) <-
  names(mieszkania) %>% chartr("ąęółćśźż", "aeolcszz", .)
mieszkania <-
  mieszkania %>%
  rename(wielkosc  = `wielkosc_(m2)`) %>%
  select(-c(data_dodania, href, adres, tytul, dostepny)) %>%
  mutate(
    liczba_wyrazow = stri_count_words(opis)
  )
mieszkania %>%
  select(-opis) %>%
  lapply(
    function(x) {
      x %>%
        table(useNA = "always") %>%
        sort(decreasing = TRUE) %>%
        head(20)
    }
  )

mieszkania <-
  mieszkania %>%
  filter(
    !(cena %in% c("Proszę o kontakt", "Wymiana/zamiana")),
    !is.na(wielkosc)
  ) %>%
  mutate(
    lokalizacja = lokalizacja %>%
      stri_replace_first_regex(", Warszawa", "") %>%
      as.factor(),
    do_wynajecia_przez = do_wynajecia_przez %>%
      plyr::mapvalues(NA, "Nie podano") %>%
      as.factor(),
    parking = parking %>%
      plyr::mapvalues(NA, "Nie podano") %>%
      as.factor(),
    liczba_pokoi = liczba_pokoi %>%
      plyr::mapvalues(NA, "Nie podano") %>%
      as.factor(),
    rodzaj_nieruchomosci = rodzaj_nieruchomosci %>%
      plyr::mapvalues(NA, "Inne") %>%
      as.factor(),
    liczba_lazienek = liczba_lazienek %>%
      plyr::mapvalues(NA, "Nie podano") %>%
      as.factor(),
    palacy = palacy %>%
      plyr::mapvalues(NA, "Tak") %>%
      as.factor(),
    przyjazne_zwierzakom = przyjazne_zwierzakom %>%
      plyr::mapvalues(NA, "Tak") %>%
      as.factor(),
    cena = stri_extract_all_regex(
      cena, "[[:digit:]]"
    ) %>%
      stri_join_list() %>%
      as.integer()
  )

mieszkania %>% summary()
```

Ponownie skrajne wartości ceny i wielkości są podejrzane. Przypatrzmy się im bliżej.

```{r}
plot(cena~wielkosc, mieszkania)

sprawdzenie11 <-
  mieszkania %>%
  filter(
    cena <= 100000,
    wielkosc <= 1000
  )

plot(cena~wielkosc, sprawdzenie11)

sprawdzenie12 <-
  mieszkania %>%
  filter(
    cena <= 10000,
    wielkosc <= 200
  )

plot(cena~wielkosc, sprawdzenie12)

sprawdzenie13 <-
  mieszkania %>%
  filter(
    between(cena, 1000, 5000),
    between(wielkosc, 20, 100)
  )

plot(cena~wielkosc, sprawdzenie13)

sprawdzenie14 <-
  mieszkania %>%
  filter(
    between(cena, 1000, 15000),
    between(wielkosc, 20, 400)
  )

plot(cena~wielkosc, sprawdzenie14)

sprawdzenie15 <-
  mieszkania %>%
  filter(
    between(cena, 1000, 10000),
    between(wielkosc, 20, 200)
  )

plot(cena~wielkosc, sprawdzenie15)

sprawdzenie16 <-
  mieszkania %>%
  filter(
    between(cena, 1000, 10000),
    between(wielkosc, 20, 100)
  )

plot(cena~wielkosc, sprawdzenie16)
```

Tym razem dane wyglądają znacznie bardziej obiecująco. Da się zauważyć korelację między wielkością mieszkania a ceną. Kawalerki zaczynają się od około 20 m^2. Duże 3-4 pokojowe mieszkania liczą sobie do 100 m^2. Skrajne wartości tej skali mają stosunek 1:4. W taki sam sposób dobrano widełki do cen. Są to typowe przedziały cen wynajmu i wielkości mieszkań.

```{r}
dane <-
  sprawdzenie13 %>%
  select(-opis)
summary(dane)
```

# Regresja liniowa

## Funkcja liniowa

```{r}
plot(cena~wielkosc, dane)
fit11 <- lm(cena~wielkosc, dane)
summary(fit11)
abline(fit11, col = "red", lwd = 2)
```

Zobaczmy jak cena zależy od pozostałych predyktorów.

```{r}
fit12 <-
  lm(cena~., dane)
summary(fit12)
plot(fit12)
```

Okazuje się, że predyktory `palacy` oraz `przyjazne_zwierzakom` nie są istotne w zbudowanym modelu. Dla uproszczenia go usuniemy te dwie kolumny. Pozostałe nieistotne parametry należą do grup czynników, z których część jest istotna, dlatego nie zostaną usunięte (należałoby wtedy usunąć też te istotne). Można zaobserwować, że stworzona nowa zmienna dotycząca liczby słów w ofercie jest bardzo istotnym predyktorem w naszym modelu.

```{r}
fit13 <-
  lm(cena~.-palacy-przyjazne_zwierzakom, dane)
summary(fit13)
plot(fit13)
```

Spróbujmy wykorzystać interakcję miedzy dwoma predyktorami - `lokalizacja` i `wielkosc`.

```{r}
fit14 <-
  lm(cena~.+lokalizacja*wielkosc, dane)
summary(fit14)
plot(fit14)
```

Okazuje się, że ta zależność jest istotna dla modelu. Otrzymujemy większe o 1.5% Adjusted R^2.

## Wielomiany

Spróbujmy teraz dopasować model nieliniowy. Najpierw od samej wielkości mieszkania.

```{r}
plot(cena~wielkosc, dane)
fit21 <-
  lm(cena~wielkosc+I(wielkosc^2), dane)
summary(fit21)
points(dane$wielkosc, fitted(fit21), col = "blue", pch = 20)
abline(fit11, col = "red", lwd = 2)
```

Podsumowanie komunikuje nam, że wielkość w drugiej potędze jest istotnym czynnikiem. Jednakże widać na powyższym wykresie i po wartości Adjusted R^2 jak nieznacznie różnią się od siebie krzywe predykcyjne.

Z ciekawości sprawdźmy jak będzie wyglądał model dla jeszcze większego stopnia wielomianu.

```{r}
plot(cena~wielkosc, dane)
fit22 <-
  lm(cena~poly(wielkosc, 6), dane)
summary(fit22)
points(dane$wielkosc, fitted(fit22), col = "green", pch = 20)
points(dane$wielkosc, fitted(fit21), col = "blue", pch = 20)
abline(fit11, col = "red", lwd = 2)
# contrast() - for qualitative predictors
```

Możemy zauważyć, że współczynnik 5 stopnia nie jest istotny dla modelu. Dodatkowo funkcja w prawym przedziale dziedziny zaczyna zbyt silnie dopasowywać się do danych (zwłaszcza na samym krańcu).

## Kroswalidacja

Tym razem do wyznaczenia błędu naszego modelu posłużymy się metodą kroswalidacji. W tym celu załadujemy odpowiednią bibliotekę ułatwiającą dalszą pracę.

```{r}
library(boot)
```

Najpierw wykorzystamy `LOOCV` czyli `Leave One Out Cross Validation`.

```{r}
fit31 <- glm(cena~wielkosc, data = dane)
# LOOCV <- cv.glm(dane, fit31)
# save(LOOCV, file = "LOOCV.Rda")
LOOCV <- get(load("LOOCV.Rda"))
LOOCV$delta
```

`LOOCV` tworzy tyle modeli ile jest obserwacji w zestawie danych, za każdym razem pomijając jedeną z nich. Następnie określa błąd sprawdzając różnicę między pominiętą obserwacją a jej przewidywaniem wynikającym z powstałego modelu. Błąd ten określa wartość delta zwróconego obiektu. Pierwsza liczba jest po prostu błędem wyliczonym na podstawie całego danych, druga zaś koryguje ten błąd ze względu na fakt, iż zestaw danych uczących był mniejszy (w tym wypadku zawsze o jedną pozycję). W tym wypadku nie widać żadnej różnicy. Efekt ten będzie bardziej widoczny dla K krotnej kroswalidacji.

Metoda cv.glm jest bardzo powolna. Dlatego efekt jej działania zapisałem wcześniej do pliku, który teraz zostaje wczytany. Czas wykonywania tej operacji trwał kilka minut. Dla znacznego przyspieszenia działania tej funkcji posłużę się następującą formułą uwzględniającą wpływ i-tej obserwacji na dopasowanie do niej krzywej.

```{r}
loocv.glm <-
  function(fit) {
    h <- lm.influence(fit)$h
    mean((residuals(fit)/(1-h))^2)
  }

loocv.glm(fit31)
```

Powodem dla którego metoda cv.glm nie korzysta docelowo z tej formuły jest fakt, że nie funkcjonuje ona w wypadku regresji logistycznej.

Teraz sprawdzimy jakie błędy będą towarzyszyć wielomianom kolejnych stopni i czy opłaca się je zastosować.

```{r}
cvBlad <- rep(0, 6)
stopien <- 1:6
for (d in stopien) {
  fit32 <- glm(cena~poly(wielkosc, d), data = dane)
  cvBlad[d] <- loocv.glm(fit32)
}

# stopien <- 1:6
# cvBlad <-
#   stopien %>%
#   sapply(
#     function(x) {
#       fit32 <- glm(cena~poly(wielkosc, x), data = dane)
#       loocv.glm(fit32)
#     }
#   )

plot(stopien, cvBlad, type = "b")
```

Na wykresie można zauważyć, że błąd przestaje maleć dla wielmianu 4 stopnia.

Teraz spróbujemy przeprowadzić K krotną kroswalidację. Standardowo za K przyjmuje się wartości 5 lub 10. W tym wypadku przyjmę tę większą.

```{r}
cvBladK10 <-
  stopien %>%
  sapply(
    function(x) {
      cv.glm(dane, fit32, K = 10)$delta[1]
    }
  )

plot(stopien, cvBlad, type = "b")
lines(stopien, cvBladK10, type = "b", col = "red")
```

K krotna kroswalidacja jest bardziej stabilną metodą. W tym przypadku widać jak podpowiada nam, że już w zasadzie funkcja liniowa jest wystarczającym modelem.

## Dobór modelu z wieloma predyktorami

Powyższy przykład pozwolił nam określić jaki stopień wielomianu jednego predyktora będzie odpowiedni dla naszego modelu. Tym razem chcemy jednak dobrać odpowiedni model z wieloma predyktorami. Jakie są nasze opcje?

### Best Subset Regression

Metoda ta porównuje wszytkie możliwe modele regresji o wszystkich możliwych wielkościach (liczbie biorących udział w tworzeniu modelu predyktorów) w poszukiwaniu najlepszego modelu dla każdego z rozmiarów. W sumie wykonuje 2^p modeli, gdzie p to lizcba predyktorów (w naszym przypadku 2^11 czyli 2048) W osiągnięciu tego celu pomoże nam biblioteka `leaps`.

```{r}
library(leaps)
```

```{r}
fit41 <- regsubsets(cena~., dane, nvmax = 11)
sum41 <- summary(fit41)
sum41
plot(sum41$cp, xlab = "Liczba predyktorów", ylab = "Cp")
points(11, sum41$cp[11], pch = 20, col = "red")
plot(fit41, scale = "Cp")
coef(fit41, 11)
```

Niestety, w tym wypadku nie widać czym charakteryzuje się ta metoda. Nie zakłada ona zagnieżdżania podzbiorów predyktorów. Zagnieżdzanie polega na tym, że każdy kolejny większy model musi opierać się na czynnikach wchodzących w skład poprzedniego modelu. Tutaj mobłoby dojść do sytuacji, gdzie dla kilku pierwszych podzbiorów przy konkretnym czynniku występują gwiazdki, następnie zaś nie pojawiają się.

Cp jest miarą błędu predykcji. Jak widać w tym przypadku najmniejszy błąd występuje dla modelu o największej liczbie predyktorów. Wcale nie musiało tak być i z większą liczbą czynników błąd mógłby zacząć rosnąć.

### Forward Stepwise Selection

Ta metodą jest jest "chciwa" w tym sensie, że zagnieżdza kolejne podzbiory czynników. Nie tworzy zatem każdej możliwej kombinacji predyktorów. Już raz dobrany czynnik wykorzystywany jest w następnym modelu. Przy dobieraniu kolejnego predyktora metoda ta dobiera najlepszą opcję porównując tylko p modeli. Zatem ogółem liczba operacji wynosi około (p^2)/2 (w naszym przypadku około 60, czyli tylko 3% w porównaniu z poprzednią metodą.

```{r}
fit42 <- regsubsets(cena~., dane, nvmax = 11, method = "forward")
sum42 <- summary(fit42)
sum42
plot(sum42$cp, xlab = "Liczba predyktorów", ylab = "Cp")
points(11, sum42$cp[11], pch = 20, col = "red")
plot(fit42, scale = "Cp")
coef(fit42, 11)
```

### Backward Stepwise Selection

Metoda ta różni się od FSS tym, że zaczyna porównywać modele zbudowane na wszystkich predyktorach i z każdym kolejnym krokiem odejmuję jeden z nich (najmniej istotny) z zestawu. Minusem tej metody jest to, że nie można użyć jej na zestawie danych gdzie występuje więcej kolumn niż wierszy.

```{r}
fit43 <- regsubsets(cena~., dane, nvmax = 11, method = "backward")
sum43 <- summary(fit43)
sum43
plot(sum43$cp, xlab = "Liczba predyktorów", ylab = "Cp")
points(11, sum43$cp[11], pch = 20, col = "red")
plot(fit43, scale = "Cp")
coef(fit43, 11)
```

### Walidacja

Tym razem podzielimy obserwacje na dwa zestawy - treningowy i walidacyjny.

```{r}
set.seed(44)
trening44 <- sample(1:nrow(dane), 9000)
fit44 <- regsubsets(cena~., dane[trening44, ], nvmax = 11, method = "forward")
```

Teraz dokonamy predykcji na obserwacjach z zestawu testowego.

```{r}
test44 <- model.matrix(cena~., dane[-trening44, ])
valBlad <-
  1:length(dane) %>%
  sapply(
    function(x) {
      coefi <- coef(fit44, id = x)
      pred <- test44[, names(coefi)]%*%coefi
      mean((dane$cena[-trening44]-pred)^2)
    }
  )
plot(
  sqrt(valBlad),
  ylim = c(400, 900),
  xlab = "Rozmiar modelu",
  ylab = "Średnia kwadratowa błędów",
  pch = 19,
  type = "b"
)
points(sqrt(fit44$rss[-1]/9000), col = "red", pch = 19, type = "b")
legend(
  "topright",
  legend = c("Trening", "Walidacja"),
  col = c("red", "black"),
  pch = 19
)
```

Na powyższym wykresie można zauważyć, że pomimo konsekwentnego spadku błędu treningowego, już przy rozmiarze modelu wynoszącym 3 błąd walidacji wypłaszcza się.

Na koniec operacje prowadzące do otrzymania takiego rezultatu zostaną ubrane w jedna funkcję.

```{r}
# there was a problem with runtime: shiny, otherwise OK

predict.regsubsets <-
  function(obiekt, formula, dane, id, ...) {
    # form <- as.formula(obiekt$call[[2]]) # object of type 'symbol' is not subsettable
    # form <- as.formula(cena ~ .) works, but not satisfactory, what if formula is different?
    # form <- obiekt$call[[2]] # object of type 'symbol' is not subsettable
    # form <- obiekt$call %>% as.character() %>% .[2] %>% as.formula() # object 'expr' not found
    # form <- as.formula(obiekt$call %>% as.character() %>% .[2]) # object 'expr' not found
    mat <- model.matrix(formula, dane)
    # mat <- model.matrix(form, dane)
    coefi <- coef(obiekt, id = id)
    mat[, names(coefi)]%*%coefi
  }
```

### Kroswalidacja

Tym razem dobierzemy model korzystając z 10 krotnej kroswalidacji.

```{r}
set.seed(45)
folds <- sample(rep(1:10, length = nrow(dane)))
table(folds)
cvBledy <- matrix(NA, 10, 11)
for (k in 1:10) {
  form <- as.formula(cena~.)
  best.fit <- regsubsets(form, dane[folds!=k, ], nvmax = 11, method = "forward")
  for (i in 1:length(dane)) {
    pred <- predict.regsubsets(best.fit, form, dane[folds==k, ], id = i)
    cvBledy[k, i] <- mean((dane$cena[folds==k]-pred)^2)
  }
}
rmse.cv <- sqrt(apply(cvBledy, 2, mean))

plot(
  sqrt(valBlad),
  ylim = c(400, 900),
  xlab = "Rozmiar modelu",
  ylab = "Średnia kwadratowa błędów",
  pch = 19,
  type = "b"
)
points(sqrt(fit44$rss[-1]/9000), col = "red", pch = 19, type = "b")
points(rmse.cv, col = "blue", pch = 19, type = "b")
legend(
  "topright",
  legend = c("10 krotna Kroswalidacja", "Trening", "Walidacja"),
  col = c("blue", "red", "black"),
  pch = 19
)
```

### Regularyzacja Tichonowa

W przeprowadzeniu Ridge Regression pomoże nam pakiet `glmnet`.

```{r}
library(glmnet)
```

`glmnet` nie korzysta z języka formuły. Trzeba zatem podzielić dane na zestaw pedyktorów i odpowiedzi. Zanim przystąpimy do działania należy też znormalizować dane (np. sprowadzić je do przedziały (-3, 3) odejmując średnią od wartości i dzieląc przez odchylenie standardowe).

```{r}
daneNorm <-
  dane %>%
  mutate(
    cena = (cena-mean(cena))/max(cena),
    wielkosc = (wielkosc-mean(wielkosc))/max(wielkosc),
    liczba_wyrazow = (liczba_wyrazow-mean(liczba_wyrazow))/max(liczba_wyrazow)
  )

x <- model.matrix(cena~.-1, dane)
y <- dane$cena
xn <- model.matrix(cena~.-1, daneNorm)
yn <- daneNorm$cena

fit45 <- glmnet(x, y, alpha = 0)
plot(fit45, xvar = "lambda", label = TRUE)
plot(fit45, xvar = "dev", label = TRUE)

cvRidge <- cv.glmnet(x, y, alpha = 0)
plot(cvRidge)

fit45 <- glmnet(xn, yn, alpha = 0)
plot(fit45, xvar = "lambda", label = TRUE)
plot(fit45, xvar = "dev", label = TRUE)

cvRidge <- cv.glmnet(xn, yn, alpha = 0)
plot(cvRidge)
```

Ridge Regression charakteryzuje się członem związanym z regularyzacją. Oznacza to, że dla dużej wartości współczynnika regularyzacji lambda będą musiały występować odpowiednio małe współczynniki Beta. Ten typ regresji opiera się więc na wszystkich predyktorach. Minimalizuje tylko ich współczynniki.

Na powyższych wykresach widać, że dla dużej lambdy współczynniki Beta zostają niemalże wyzerowane oraz że najmniejszy błąd otrzymujemy dla najmniejszej wartości lambda. Oznacza to, że udział każdego z czynników jest istotny dla budowanego modelu (posiada odpowiednio duży stojący przy nim współczynnik Beta). Potwierdza to więc poprzednie obserwacje, gdzie najskuteczniejszy model korzystał ze wszystkich 11 predyktorów. Fraction Deviance Explained jest jak R^2.

### Lasso

Lasso czyli `Least Absolute Shrinkage and Selection Operator` różni się od poprzedniej metody elementem regulującym. Tym razem wartości Beta mogą zostać sprowadzone do zera, przez co część predyktorów może nie wziąć udziału w budowie modelu.

```{r}
fit46 <- glmnet(x, y)
plot(fit46, xvar = "lambda", label = TRUE)
plot(fit46, xvar = "dev", label = TRUE)

cvLasso <- cv.glmnet(x, y)
plot(cvLasso)

fit47 <- glmnet(xn, yn)
plot(fit47, xvar = "lambda", label = TRUE)
plot(fit47, xvar = "dev", label = TRUE)

cvLassoN <- cv.glmnet(xn, yn)
plot(cvLassoN)

(coef(cvLassoN) %>% as.vector() != 0) %>% sum()
```

Na sam koniec spróbujmy jeszcze dobrać parametr lambda za pomocą metody walidacji (wcześniejszy set treningowy i set testowy).

```{r}
lasso.tr <- glmnet(x[trening44, ], y[trening44])
lasso.tr
pred <- predict(lasso.tr, x[-trening44, ])
dim(pred)
rmse <- sqrt(apply((y[-trening44]-pred)^2, 2, mean))
plot(log(lasso.tr$lambda), rmse, type = "b", xlab = "Log(lambda)")
lam.best <- lasso.tr$lambda[order(rmse)[1]]
lam.best
lam.best %>% log()
coef(lasso.tr, s = lam.best)
```

Można zauważyć, że w tym wypadku otrzymaliśmy model, który nie jest najlepszym z możliwych, ale też nie jest gorszy niż najbardziej elastyczny proponowany przez kroswalidację.